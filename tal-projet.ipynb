{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/c/c7/HEIG-VD_Logo_96x29_RVB_ROUGE.png\" alt=\"HEIG-VD Logo\" width=\"250\"/>\n",
    "\n",
    "# Cours TAL – Mini-projet\n",
    "# Classification de dépêches d’agence avec NLTK\n",
    "\n",
    "> Tiago Povoa Quinteiro\n",
    "\n",
    "**Modalités du projet**\n",
    "\n",
    "L’objectif de ce projet est de réaliser des expériences de classification de documents sous NLTK avec\n",
    "le corpus de dépêches Reuters. Le projet est individuel : vous êtes responsable des différentes options\n",
    "choisies, et en principe les résultats de chaque projet seront différents. Le projet sera jugé sur la\n",
    "qualité des expériences (correction méthodologique) mais aussi sur la discussion des options\n",
    "explorées.\n",
    "\n",
    "Vous devez remettre un notebook Jupyter présentant vos choix, votre code, vos résultats et les\n",
    "discussions. Le notebook devra déjà contenir les résultats des exécutions, mais pourra être ré-exécuté\n",
    "par le professeur en vue d’une vérification.\n",
    "\n",
    "Vous devrez en outre faire une courte présentation orale (5-7 min.) et répondre aux questions sur\n",
    "votre projet (5-7 min.) lors d’une séance sur Teams (15 min.) avec le professeur et l’assistant.\n",
    "\n",
    "**Description des expériences**\n",
    "\n",
    "1. **L’objectif général** est d’explorer au moins deux aspects parmi les multiples choix qui se posent lors de la création d’un système de classification de textes.\n",
    "2. **Données** : les dépêches du corpus Reuters, tel qu’il est fourni par NLTK. Vous respecterez notamment la division en données d’entraînement (train) et données de test.\n",
    "3. **Hyper-paramètres** : la définition d’un classifieur comporte un grand nombre de choix de conception, dans plusieurs dimensions. Dans ce projet, et pour chaque objectif de classification (voir ci-dessous) vous explorerez deux dimensions. Pour chaque dimension, vous comparerez au moins deux options pour trouver laquelle fournit le meilleur score, et vous tenterez d’expliquer pourquoi. Vous pourrez choisir parmi les options suivantes :\n",
    "\n",
    "    a. options de prétraitement des textes : stopwords, lemmatisation, tout en minuscules.\n",
    "    \n",
    "    b. options de représentation : présence/absence de mots indicateurs, nombre de mots indicateurs ; présence/absence/nombre de bigrammes, trigrammes ; autres traits : longueur de la dépêche, rapport tokens/types.\n",
    "    \n",
    "    c. classifieurs et leurs paramètres : divers choix possibles (voir la documentation).\n",
    "    \n",
    "    \n",
    "4. **Objectif de classification** : vous devrez construire quatre classifieurs. Vous choisirez les meilleurs hyper-paramètres pour chaque classifieur sans regarder les résultats sur les données de test NLTK, mais en divisant les données d’entraînement NLTK en 80% train et 20% dev. Vous ferez ensuite l’entraînement final sur l’intégralité des données d’entraînement.\n",
    "\n",
    "    a. Veuillez d’abord définir et entraîner trois classifieurs binaires, correspondant à trois catégories de votre choix. Chaque classifieur prédit si une dépêche appartient ou non à la catégorie, i.e. si elle doit recevoir ou non l’étiquette respective. Veuillez construire un premier classifieur binaire pour une étiquette que vous choisirez librement parmi les trois suivantes : ‘money-fx’, ‘interest’, ou ‘money-supply’. Le deuxième classifieur binaire concernera une étiquette de votre choix parmi : ‘grain’, ‘wheat’, ‘corn’. Enfin, le troisième sera choisi parmi : ‘crude’, ‘nat-gas’, ‘gold’.\n",
    "        - Veuillez donner les scores de rappel, précision et f-mesure de chacun des trois classifieurs que vous avez conçus et entraînés.\n",
    "    \n",
    "    b. On vous demande également de définir un quatrième classifieur qui assigne l’une des trois étiquettes que vous avez choisies ci-dessus plus la catégorie ‘other’ (il assigne donc une seule étiquette parmi quatre). Vous devrez adapter légèrement les données, car un très petit nombre de dépêches (combien ?) sont en réalité annotées avec plusieurs de ces étiquettes, et vous n’en retiendrez que la première.\n",
    "        - Veuillez évaluer ce classifieur en termes de rappel, précision et f-mesure pour chacune des trois étiquettes choisies ci-dessus, et comparer ces trois scores à ceux des trois classifieurs binaires précédents.\n",
    "    \n",
    "5. **Documentation** : livre NLTK, chapitre 2 pour le corpus Reuters, chapitre 6 pour la classification, et http://www.nltk.org/howto/classify.html pour les classifieurs dans NLTK ; Introduction to Information Retrieval (https://nlp.stanford.edu/IR-book/information-retrieval-book.html), chapitre 13, pour une discussion de méthodes de classification, et des exemples de scores obtenus sur certaines étiquettes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Définition des fonctions\n",
    "\n",
    "On va définir des fonctions pour: obtenir le vocabulaire, filtrer, trouver la catégorie adéquate et préparer les données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import reuters\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in reuters: 1720901 total - unique: 41600 \n",
      "\n",
      "After removals: 964625 total - unique: 30778 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def remove_stop_words(words):\n",
    "    \"\"\"\n",
    "    Remove english stopwords and words of length 1\n",
    "    inspiration: http://www.nltk.org/book/ch02.html\n",
    "    words: a list of words\n",
    "    return words lower case without stopwords\n",
    "    \"\"\"\n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "    return [w.lower() for w in words if len(w) > 1 and w.lower() not in stopwords]\n",
    "\n",
    "\n",
    "def remove_punctuation(words):\n",
    "    \"\"\"\n",
    "    inspiration: https://machinelearningmastery.com/clean-text-machine-learning-python/\n",
    "    \"\"\"\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    return [w.translate(table) for w in words]\n",
    "\n",
    "\n",
    "def filter_words(words, rm_punctuation=True, rm_stopwords=True):\n",
    "    if rm_punctuation:\n",
    "        words = remove_punctuation(words)\n",
    "    if rm_stopwords:\n",
    "        words = remove_stop_words(words)\n",
    "    \n",
    "    return words\n",
    "\n",
    "\n",
    "def get_reuters_vocab(sample_size=500, rm_punctuation=True, rm_stopwords=True):\n",
    "    words = reuters.words()         \n",
    "    \n",
    "    fdist = FreqDist(words)\n",
    "    \n",
    "    print('Number of words in reuters: {} total - unique: {} \\n'.format(fdist.N(), fdist.B()))\n",
    "    \n",
    "    fdist = FreqDist(filter_words(words, rm_punctuation, rm_stopwords) )\n",
    "\n",
    "    print('After removals: {} total - unique: {} \\n'.format(fdist.N(), fdist.B()))\n",
    "\n",
    "    return [w[0] for w in fdist.most_common(sample_size)]\n",
    "\n",
    "\n",
    "def vocab_dic(vocab):\n",
    "    \"\"\"\n",
    "    return a vocabulary list as a dictionnary with all values\n",
    "    set to False\n",
    "    \"\"\"\n",
    "    return {w:False for w in vocab}\n",
    "\n",
    "\n",
    "reuters_vocabulary_dic = vocab_dic(get_reuters_vocab())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _category(fileid, wanted_category):\n",
    "    \"\"\"\n",
    "    return a specific category given a fileid. If not found, returns \"not_category\"\n",
    "    \"\"\"\n",
    "    return wanted_category if wanted_category in reuters.categories(fileid) else f'not_{wanted_category}'\n",
    "\n",
    "\n",
    "def _words_dic(vocab_dic, words):\n",
    "    _tmp_dic = dict()\n",
    "    _tmp_dic.update(vocab_dic)\n",
    "        \n",
    "    for w in words:\n",
    "        if w in vocab_dic:\n",
    "            _tmp_dic[w] = True\n",
    "            \n",
    "    return _tmp_dic\n",
    "            \n",
    "\n",
    "def prepare_reuters_data(vocab_dic, wanted_category, rm_punctuation=True, rm_stopwords=True):\n",
    "    train_data = []\n",
    "    test_data = []\n",
    "\n",
    "    for fileid in reuters.fileids():\n",
    "        category = _category(fileid, wanted_category)\n",
    "        words = reuters.words(fileid)\n",
    "        words = filter_words(words, rm_punctuation, rm_stopwords)\n",
    "        dic = _words_dic(vocab_dic, words)\n",
    "        if fileid.startswith('test'):\n",
    "            test_data.append([dic, category])\n",
    "        else:\n",
    "            train_data.append([dic, category])\n",
    "                \n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7769 3019\n",
      "6215 603\n"
     ]
    }
   ],
   "source": [
    "def prepare_pre_cut(train_data, test_data):\n",
    "    cut_train = int(len(train_data) * 0.8 )\n",
    "    cut_test = int(len(test_data) * 0.2 )\n",
    "    return train_data[0:cut_train], test_data[0:cut_test]\n",
    "\n",
    "\n",
    "reuters_train_data, reuters_test_data = prepare_reuters_data(reuters_vocabulary_dic, 'money-supply')\n",
    "print(len(reuters_train_data), len(reuters_test_data))\n",
    "\n",
    "cut_reuters_train_data, cut_reuters_test_data = prepare_pre_cut(reuters_train_data, reuters_test_data)\n",
    "print(len(cut_reuters_train_data), len(cut_reuters_test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.classify import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier accuracy percent: 93.69817578772802\n",
      "Most Informative Features\n",
      "                     cts = True           not_mo : money- =     21.9 : 1.0\n",
      "                     fed = True           money- : not_mo =     21.8 : 1.0\n",
      "                      vs = True           not_mo : money- =     20.5 : 1.0\n",
      "                 company = True           not_mo : money- =     18.7 : 1.0\n",
      "                    corp = True           not_mo : money- =     18.3 : 1.0\n",
      "                  supply = True           money- : not_mo =     16.8 : 1.0\n",
      "                   money = True           money- : not_mo =     15.4 : 1.0\n",
      "                     000 = True           not_mo : money- =     13.2 : 1.0\n",
      "                 reserve = True           money- : not_mo =     11.2 : 1.0\n",
      "              bundesbank = True           money- : not_mo =     10.7 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier_2 = nltk.NaiveBayesClassifier.train(cut_reuters_train_data)\n",
    "print(\"Classifier accuracy percent:\",(nltk.classify.accuracy(classifier_2, cut_reuters_test_data))*100)\n",
    "classifier_2.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections \n",
    "from nltk.metrics import precision, recall, f_measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_data(wanted_category, cut=True, sampleSize=500, rm_punctuation=True, rm_stopwords=True):\n",
    "    reuters_vocabulary_dic = vocab_dic(get_reuters_vocab(rm_punctuation, rm_stopwords))\n",
    "    \n",
    "    reuters_train_data, reuters_test_data = prepare_reuters_data(reuters_vocabulary_dic, wanted_category)\n",
    "\n",
    "    if cut:\n",
    "        reuters_train_data, reuters_test_data = prepare_pre_cut(reuters_train_data, reuters_test_data)\n",
    "        \n",
    "    return reuters_train_data, reuters_test_data\n",
    "    \n",
    "    \n",
    "def eval_classifier(trained_classifier, test_data, label):\n",
    "    \"\"\"\n",
    "    Inspiration: https://streamhacker.com/2010/05/17/text-classification-sentiment-analysis-precision-recall/\n",
    "    \"\"\"\n",
    "    ref_set = collections.defaultdict(set)\n",
    "    test_set = collections.defaultdict(set)\n",
    "    \n",
    "    for i, (feats, true_category) in enumerate(test_data):\n",
    "        ref_set[true_category].add(i)\n",
    "        observed = trained_classifier.classify(feats)\n",
    "        test_set[observed].add(i)\n",
    "    \n",
    "    print(ref_set, test_set)\n",
    "    print('Classifier evaluation: ')\n",
    "    print( 'Precision:', precision(ref_set[label], test_set[label]) )\n",
    "    print( 'Recall:', recall(ref_set[label], test_set[label]) )\n",
    "    print( 'F-measure:', f_measure(ref_set[label], test_set[label]) )\n",
    "    \n",
    "    \n",
    "def run_classifier(classifier, wanted_category, cut=True, sampleSize=500, rm_punctuation=True, rm_stopwords=True):\n",
    "    train_data, test_data = obtain_data(wanted_category, cut, sampleSize, rm_punctuation, rm_stopwords)\n",
    "    \n",
    "    print(f'{classifier}')\n",
    "    \n",
    "    trained_classifier = classifier.train(train_data)\n",
    "    \n",
    "    eval_classifier(trained_classifier, test_data, wanted_category)\n",
    "\n",
    "    \n",
    "categories = {\n",
    "    0: ['money-fx', 'interest', 'money-supply'],\n",
    "    1: ['grain', 'wheat', 'corn'],\n",
    "    2: ['crude', 'nat-gas', 'gold']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in reuters: 1720901 total - unique: 41600 \n",
      "\n",
      "After removals: 964625 total - unique: 30778 \n",
      "\n",
      "<class 'nltk.classify.naivebayes.NaiveBayesClassifier'>\n",
      "defaultdict(<class 'set'>, {'not_money-fx': {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 280, 281, 282, 283, 284, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 318, 320, 321, 324, 325, 329, 332, 333, 334, 335, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 362, 363, 364, 365, 369, 370, 371, 372, 373, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 430, 431, 432, 433, 435, 436, 438, 439, 440, 441, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 456, 457, 458, 459, 460, 461, 462, 463, 464, 466, 467, 468, 469, 470, 472, 473, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602}, 'money-fx': {11, 17, 279, 285, 286, 32, 43, 45, 429, 434, 52, 437, 442, 317, 319, 322, 67, 195, 323, 326, 327, 328, 455, 330, 331, 207, 336, 465, 83, 471, 218, 474, 361, 366, 367, 368, 114, 374}}) defaultdict(<class 'set'>, {'not_money-fx': {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602}})\n",
      "Classifier evaluation: \n",
      "Precision: None\n",
      "Recall: 0.0\n",
      "F-measure: None\n"
     ]
    }
   ],
   "source": [
    "run_classifier(nltk.NaiveBayesClassifier, categories[0][0], cut=True, sampleSize=5000, rm_punctuation=True, rm_stopwords=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
