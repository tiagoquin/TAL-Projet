{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/c/c7/HEIG-VD_Logo_96x29_RVB_ROUGE.png\" alt=\"HEIG-VD Logo\" width=\"250\"/>\n",
    "\n",
    "# Cours TAL – Mini-projet\n",
    "# Classification de dépêches d’agence avec NLTK\n",
    "\n",
    "> Tiago Povoa Quinteiro\n",
    "\n",
    "**Modalités du projet**\n",
    "\n",
    "L’objectif de ce projet est de réaliser des expériences de classification de documents sous NLTK avec\n",
    "le corpus de dépêches Reuters. Le projet est individuel : vous êtes responsable des différentes options\n",
    "choisies, et en principe les résultats de chaque projet seront différents. Le projet sera jugé sur la\n",
    "qualité des expériences (correction méthodologique) mais aussi sur la discussion des options\n",
    "explorées.\n",
    "\n",
    "Vous devez remettre un notebook Jupyter présentant vos choix, votre code, vos résultats et les\n",
    "discussions. Le notebook devra déjà contenir les résultats des exécutions, mais pourra être ré-exécuté\n",
    "par le professeur en vue d’une vérification.\n",
    "\n",
    "Vous devrez en outre faire une courte présentation orale (5-7 min.) et répondre aux questions sur\n",
    "votre projet (5-7 min.) lors d’une séance sur Teams (15 min.) avec le professeur et l’assistant.\n",
    "\n",
    "**Description des expériences**\n",
    "\n",
    "1. **L’objectif général** est d’explorer au moins deux aspects parmi les multiples choix qui se posent lors de la création d’un système de classification de textes.\n",
    "2. **Données** : les dépêches du corpus Reuters, tel qu’il est fourni par NLTK. Vous respecterez notamment la division en données d’entraînement (train) et données de test.\n",
    "3. **Hyper-paramètres** : la définition d’un classifieur comporte un grand nombre de choix de conception, dans plusieurs dimensions. Dans ce projet, et pour chaque objectif de classification (voir ci-dessous) vous explorerez deux dimensions. Pour chaque dimension, vous comparerez au moins deux options pour trouver laquelle fournit le meilleur score, et vous tenterez d’expliquer pourquoi. Vous pourrez choisir parmi les options suivantes :\n",
    "\n",
    "    a. options de prétraitement des textes : stopwords, lemmatisation, tout en minuscules.\n",
    "    \n",
    "    b. options de représentation : présence/absence de mots indicateurs, nombre de mots indicateurs ; présence/absence/nombre de bigrammes, trigrammes ; autres traits : longueur de la dépêche, rapport tokens/types.\n",
    "    \n",
    "    c. classifieurs et leurs paramètres : divers choix possibles (voir la documentation).\n",
    "    \n",
    "    \n",
    "4. **Objectif de classification** : vous devrez construire quatre classifieurs. Vous choisirez les meilleurs hyper-paramètres pour chaque classifieur sans regarder les résultats sur les données de test NLTK, mais en divisant les données d’entraînement NLTK en 80% train et 20% dev. Vous ferez ensuite l’entraînement final sur l’intégralité des données d’entraînement.\n",
    "\n",
    "    a. Veuillez d’abord définir et entraîner trois classifieurs binaires, correspondant à trois catégories de votre choix. Chaque classifieur prédit si une dépêche appartient ou non à la catégorie, i.e. si elle doit recevoir ou non l’étiquette respective. Veuillez construire un premier classifieur binaire pour une étiquette que vous choisirez librement parmi les trois suivantes : ‘money-fx’, ‘interest’, ou ‘money-supply’. Le deuxième classifieur binaire concernera une étiquette de votre choix parmi : ‘grain’, ‘wheat’, ‘corn’. Enfin, le troisième sera choisi parmi : ‘crude’, ‘nat-gas’, ‘gold’.\n",
    "        - Veuillez donner les scores de rappel, précision et f-mesure de chacun des trois classifieurs que vous avez conçus et entraînés.\n",
    "    \n",
    "    b. On vous demande également de définir un quatrième classifieur qui assigne l’une des trois étiquettes que vous avez choisies ci-dessus plus la catégorie ‘other’ (il assigne donc une seule étiquette parmi quatre). Vous devrez adapter légèrement les données, car un très petit nombre de dépêches (combien ?) sont en réalité annotées avec plusieurs de ces étiquettes, et vous n’en retiendrez que la première.\n",
    "        - Veuillez évaluer ce classifieur en termes de rappel, précision et f-mesure pour chacune des trois étiquettes choisies ci-dessus, et comparer ces trois scores à ceux des trois classifieurs binaires précédents.\n",
    "    \n",
    "5. **Documentation** : livre NLTK, chapitre 2 pour le corpus Reuters, chapitre 6 pour la classification, et http://www.nltk.org/howto/classify.html pour les classifieurs dans NLTK ; Introduction to Information Retrieval (https://nlp.stanford.edu/IR-book/information-retrieval-book.html), chapitre 13, pour une discussion de méthodes de classification, et des exemples de scores obtenus sur certaines étiquettes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function definitions\n",
    "\n",
    "Here are some util functions to remove stop words, lemmatization, punctuation, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import reuters\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in reuters: 1720901 total - unique: 41600 \n",
      "\n",
      "After removals: 961132 total - unique: 29649 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def remove_stop_words(words):\n",
    "    \"\"\"\n",
    "    Remove english stopwords and words of length 1\n",
    "    inspiration: http://www.nltk.org/book/ch02.html\n",
    "    words: a list of words\n",
    "    return words lower case without stopwords\n",
    "    \"\"\"\n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "    return [w.lower() for w in words if len(w) > 1 and w.lower() not in stopwords]\n",
    "\n",
    "\n",
    "def remove_punctuation(words):\n",
    "    \"\"\"\n",
    "    inspiration: https://machinelearningmastery.com/clean-text-machine-learning-python/\n",
    "    \"\"\"\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    return [w.translate(table) for w in words]\n",
    "\n",
    "\n",
    "def do_lemmatize(words):\n",
    "    wnl = WordNetLemmatizer() \n",
    "    return [wnl.lemmatize(w) for w in words]\n",
    "\n",
    "\n",
    "def filter_words(words, rm_punctuation, rm_stopwords, lemmatize):\n",
    "    if rm_punctuation:\n",
    "        words = remove_punctuation(words)\n",
    "        \n",
    "    if lemmatize:\n",
    "        words = do_lemmatize(words)\n",
    "\n",
    "    if rm_stopwords:\n",
    "        words = remove_stop_words(words)\n",
    "            \n",
    "    return words\n",
    "\n",
    "\n",
    "def get_reuters_vocab(sample_size, rm_punctuation, rm_stopwords, lemmatize):\n",
    "    \"\"\"\n",
    "    return a sample of words from reuters\n",
    "    \"\"\"\n",
    "    words = reuters.words()         \n",
    "    \n",
    "    fdist = FreqDist(words)\n",
    "    \n",
    "    print('Number of words in reuters: {} total - unique: {} \\n'.format(fdist.N(), fdist.B()))\n",
    "    \n",
    "    fdist = FreqDist(filter_words(words, rm_punctuation, rm_stopwords, lemmatize) )\n",
    "\n",
    "    print('After removals: {} total - unique: {} \\n'.format(fdist.N(), fdist.B()))\n",
    "\n",
    "    return [w[0] for w in fdist.most_common(sample_size)]\n",
    "\n",
    "\n",
    "def vocab_dic(vocab):\n",
    "    \"\"\"\n",
    "    return a vocabulary list as a dictionnary with all values\n",
    "    set to False\n",
    "    \"\"\"\n",
    "    return {w:False for w in vocab}\n",
    "\n",
    "\n",
    "reuters_vocabulary_dic = vocab_dic(get_reuters_vocab(500, True, True, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _category(fileid, wanted_category):\n",
    "    \"\"\"\n",
    "    return a specific category given a fileid. If not found, returns \"not_category\"\n",
    "    \"\"\"\n",
    "    return wanted_category if wanted_category in reuters.categories(fileid) else f'not_{wanted_category}'\n",
    "\n",
    "\n",
    "def _words_dic(vocab_dic, words):\n",
    "    _tmp_dic = dict()\n",
    "    _tmp_dic.update(vocab_dic)\n",
    "    \n",
    "    for w in words:\n",
    "        if w in vocab_dic:\n",
    "            _tmp_dic[w] = True\n",
    "            \n",
    "    return _tmp_dic\n",
    "            \n",
    "\n",
    "def prepare_reuters_data(vocab_dic, wanted_category, rm_punctuation, rm_stopwords, lemmatize):\n",
    "    __train_data = []\n",
    "    __test_data = []\n",
    "\n",
    "    for fileid in reuters.fileids():\n",
    "        category = _category(fileid, wanted_category)\n",
    "        words = reuters.words(fileid)\n",
    "        words = filter_words(words, rm_punctuation, rm_stopwords, lemmatize)\n",
    "        dic = _words_dic(vocab_dic, words)\n",
    "        if fileid.startswith('test'):\n",
    "            __train_data.append([dic, category])\n",
    "        else:\n",
    "            __test_data.append([dic, category])\n",
    "                \n",
    "    return __test_data, __test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7769 7769\n",
      "6215 1554\n"
     ]
    }
   ],
   "source": [
    "def prepare_pre_cut(train_data, test_data):\n",
    "    \"\"\"\n",
    "    As asked by the assignement, we have to cut on train data\n",
    "    between 80% for training and 20% as dev (here named test)\n",
    "    \"\"\"\n",
    "    cut_train = int(len(train_data) * 0.8 )\n",
    "    # cut_test = int(len(train_data) * 0.2 )\n",
    "    return train_data[0:cut_train], train_data[cut_train:]\n",
    "\n",
    "\n",
    "reuters_train_data, reuters_test_data = prepare_reuters_data(reuters_vocabulary_dic, 'money-supply', True, True, True)\n",
    "print(len(reuters_train_data), len(reuters_test_data))\n",
    "\n",
    "cut_reuters_train_data, cut_reuters_test_data = prepare_pre_cut(reuters_train_data, reuters_test_data)\n",
    "print(len(cut_reuters_train_data), len(cut_reuters_test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.classify import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier_2 = nltk.NaiveBayesClassifier.train(cut_reuters_train_data)\n",
    "# print(\"Classifier accuracy percent:\",(nltk.classify.accuracy(classifier_2, cut_reuters_test_data))*100)\n",
    "# classifier_2.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections \n",
    "from nltk.metrics import precision, recall, f_measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_data(wanted_category, cut, sampleSize, rm_punctuation, rm_stopwords, lemmatize):\n",
    "    _vocab_dic = vocab_dic(get_reuters_vocab(sampleSize, rm_punctuation, rm_stopwords,  lemmatize))\n",
    "    \n",
    "    _train_data, _test_data = prepare_reuters_data(_vocab_dic, wanted_category, rm_punctuation, rm_stopwords,  lemmatize)\n",
    "\n",
    "    if cut:\n",
    "        _train_data, _test_data = prepare_pre_cut(_train_data, _test_data)\n",
    "        \n",
    "    return _train_data, _test_data\n",
    "    \n",
    "    \n",
    "def eval_classifier(trained_classifier, test_data, label):\n",
    "    \"\"\"\n",
    "    Inspiration: https://streamhacker.com/2010/05/17/text-classification-sentiment-analysis-precision-recall/\n",
    "    \"\"\"\n",
    "    ref_set = collections.defaultdict(set)\n",
    "    test_set = collections.defaultdict(set)\n",
    "    \n",
    "    for i, (feats, true_label) in enumerate(test_data):\n",
    "        ref_set[true_label].add(i)\n",
    "        observed = trained_classifier.classify(feats)\n",
    "        \n",
    "        test_set[observed].add(i)\n",
    "\n",
    "    print('Classifier evaluation: ')\n",
    "    print( 'Precision:', precision(ref_set[label], test_set[label]) )\n",
    "    print( 'Recall:', recall(ref_set[label], test_set[label]) )\n",
    "    print( 'F-measure:', f_measure(ref_set[label], test_set[label]) )\n",
    "    \n",
    "    \n",
    "def run_classifier(classifier, wanted_category, cut=True, sampleSize=500, rm_punctuation=True, rm_stopwords=True, lemmatize=True):\n",
    "    train_data, test_data = obtain_data(wanted_category, cut, sampleSize, rm_punctuation, rm_stopwords,  lemmatize)\n",
    "    \n",
    "    print(f'{classifier}')\n",
    "    \n",
    "    trained_classifier = None\n",
    "    if f'{classifier}' == \"<class 'nltk.classify.maxent.MaxentClassifier'>\":\n",
    "        print('Hello Maxent')\n",
    "        trained_classifier = classifier.train(train_data, trace=3)\n",
    "    else:\n",
    "        trained_classifier = classifier.train(train_data)\n",
    "    \n",
    "    eval_classifier(trained_classifier, test_data, wanted_category)\n",
    "\n",
    "    \n",
    "categories = {\n",
    "    0: ['money-fx', 'interest', 'money-supply'],\n",
    "    1: ['grain', 'wheat', 'corn'],\n",
    "    2: ['crude', 'nat-gas', 'gold']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4a\n",
    "\n",
    "## Naive Bayes classifier\n",
    "\n",
    "> Chosen category: money-fx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in reuters: 1720901 total - unique: 41600 \n",
      "\n",
      "After removals: 964625 total - unique: 30778 \n",
      "\n",
      "<class 'nltk.classify.naivebayes.NaiveBayesClassifier'>\n",
      "Classifier evaluation: \n",
      "Precision: 0.2757009345794392\n",
      "Recall: 0.4306569343065693\n",
      "F-measure: 0.3361823361823361\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes classifier\n",
    "# Hyper paramters\n",
    "CUT=True\n",
    "SAMPLE_SIZE=10\n",
    "RM_PONCTUATION=True\n",
    "RM_STOPWORDS=True\n",
    "LEMMATIZE=False\n",
    "\n",
    "run_classifier(NaiveBayesClassifier, categories[0][0], CUT, SAMPLE_SIZE, RM_PONCTUATION, RM_STOPWORDS, LEMMATIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the examples below, the data is always CUT=True\n",
    "The category word chosen was 'money-fx' since it was the first. Why not?\n",
    "\n",
    "### Test 1: Filtering\n",
    "\n",
    "#### Variant 1: No filter\n",
    "\n",
    "* SAMPLE_SIZE=5000\n",
    "\n",
    "Every other parameter to false\n",
    "\n",
    "\n",
    "* Precision: 0.3879003558718861\n",
    "* Recall: 0.7956204379562044\n",
    "* F-measure: 0.5215311004784688\n",
    "\n",
    "#### Variant 2: Punctuation\n",
    "\n",
    "Adding the punctuation filter\n",
    "\n",
    "* Precision: 0.39636363636363636\n",
    "* Recall: 0.7956204379562044\n",
    "* F-measure: 0.529126213592233\n",
    "\n",
    "Adding the punctuation filter improves a little bit the precision.\n",
    "\n",
    "#### Variant 3: Stop word\n",
    "\n",
    "* Precision: 0.4703196347031963\n",
    "* Recall: 0.7518248175182481\n",
    "* F-measure: 0.5786516853932584\n",
    "\n",
    "It does significantly improve the precision.\n",
    "The recall is a bit lower, the F-Measure improves (since we improve one of it's parameters)\n",
    "\n",
    "#### Variant 4: Lemmatization\n",
    "\n",
    "* Precision: 0.39636363636363636\n",
    "* Recall: 0.7956204379562044\n",
    "* F-measure: 0.529126213592233\n",
    "\n",
    "This variant looks very similar to punctuation. We lose too much by not using stop words\n",
    "\n",
    "#### Variant 5: Lemmatization and Stop word\n",
    "\n",
    "* Precision: 0.46017699115044247\n",
    "* Recall: 0.7591240875912408\n",
    "* F-measure: 0.5730027548209367\n",
    "\n",
    "By adding lemmatization, we lose a tiny bit on precision and a tinier bit in recall.\n",
    "Since F-Measure is a metric using both, we shall use it to decide: It seems it does not improve.\n",
    "\n",
    "#### Conclusion\n",
    "\n",
    "The better F-Measure was variant 3 (punctuation, stop words, no lemmatization).\n",
    "\n",
    "### Test 2:  Vocabulary size\n",
    "\n",
    "#### 500 \n",
    "\n",
    "* Precision: 0.45564516129032256\n",
    "* Recall: 0.8248175182481752\n",
    "* F-measure: 0.587012987012987\n",
    "\n",
    "#### 1250\n",
    "\n",
    "* Precision: 0.4826086956521739\n",
    "* Recall: 0.8102189781021898\n",
    "* F-measure: 0.6049046321525885\n",
    "\n",
    "#### 2500\n",
    "\n",
    "* Precision: 0.5045871559633027\n",
    "* Recall: 0.8029197080291971\n",
    "* F-measure: 0.6197183098591549\n",
    "\n",
    "#### 5000\n",
    "\n",
    "* Precision: 0.4703196347031963\n",
    "* Recall: 0.7518248175182481\n",
    "* F-measure: 0.5786516853932584\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "The best score was obtained with 2500 in Vocabulary size and by filtering stop words.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier\n",
    "\n",
    "> chosen category: corn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in reuters: 1720901 total - unique: 41600 \n",
      "\n",
      "After removals: 1720901 total - unique: 39425 \n",
      "\n",
      "<class 'nltk.classify.decisiontree.DecisionTreeClassifier'>\n",
      "Classifier evaluation: \n",
      "Precision: 0.84\n",
      "Recall: 0.6774193548387096\n",
      "F-measure: 0.7499999999999999\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Classifier\n",
    "# Hyper paramters\n",
    "CUT=True\n",
    "SAMPLE_SIZE=1250\n",
    "RM_PONCTUATION=True\n",
    "RM_STOPWORDS=False\n",
    "LEMMATIZE=True\n",
    "\n",
    "run_classifier(DecisionTreeClassifier, categories[1][2], CUT, SAMPLE_SIZE, RM_PONCTUATION, RM_STOPWORDS, LEMMATIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1: Vocabulary size\n",
    "\n",
    "#### Variant A: 5000 all filters\n",
    "\n",
    "* Precision: 0.9333333333333333\n",
    "* Recall: 0.9032258064516129\n",
    "* F-measure: 0.9180327868852458\n",
    "\n",
    "#### Variant B: 2500 all filters\n",
    "\n",
    "* Precision: 0.9655172413793104\n",
    "* Recall: 0.9032258064516129\n",
    "* F-measure: 0.9333333333333333\n",
    "\n",
    "#### Variant C: 1250 all filters\n",
    "\n",
    "* Precision: 0.9666666666666667\n",
    "* Recall: 0.9354838709677419\n",
    "* F-measure: 0.9508196721311474\n",
    "\n",
    "#### Variant D: 500 All filters\n",
    "\n",
    "* Precision: 1.0\n",
    "* Recall: 0.6774193548387096\n",
    "* F-measure: 0.8076923076923077\n",
    "\n",
    "### Test 2: \n",
    "\n",
    "* SAMPLE_SIZE=1250\n",
    "\n",
    "#### Variant A: No filters\n",
    "\n",
    "* Precision: 0.84\n",
    "* Recall: 0.6774193548387096\n",
    "* F-measure: 0.7499999999999999\n",
    "\n",
    "#### Variant B: Punctuation\n",
    "\n",
    "* Precision: 0.84\n",
    "* Recall: 0.6774193548387096\n",
    "* F-measure: 0.7499999999999999\n",
    "\n",
    "Removing punctuation didn't change anything.\n",
    "\n",
    "#### Variant C: Stop words\n",
    "\n",
    "* Precision: 0.9666666666666667\n",
    "* Recall: 0.9354838709677419\n",
    "* F-measure: 0.9508196721311474\n",
    "\n",
    "It is totally identical to the variant with all filters.\n",
    "\n",
    "#### Variant D: Lemmatization (no stop words filtering)\n",
    "\n",
    "* Precision: 0.84\n",
    "* Recall: 0.6774193548387096\n",
    "* F-measure: 0.7499999999999999\n",
    "\n",
    "Adding lemmatization didn't help.\n",
    "\n",
    "#### Conclusion\n",
    "\n",
    "The only parameter who does help it the decision tree is removing stop words.\n",
    "Adding the two other filters doesn't seem to change the scores.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "Best parameters: 1250 vocabulary size, Stop words on (you can add the other filters but it doesn't seem to change something)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MaxentClassifier\n",
    "> chose category: gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in reuters: 1720901 total - unique: 41600 \n",
      "\n",
      "After removals: 961132 total - unique: 29649 \n",
      "\n",
      "<class 'nltk.classify.maxent.MaxentClassifier'>\n",
      "Hello Maxent\n",
      "  ==> Training (100 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -0.69315        0.988\n",
      "             2          -0.11210        0.988\n",
      "             3          -0.03275        0.988\n",
      "             4          -0.01793        0.988\n",
      "             5          -0.01410        0.988\n",
      "             6          -0.01287        0.988\n",
      "             7          -0.01240        0.988\n",
      "             8          -0.01221        0.988\n",
      "             9          -0.01212        0.988\n",
      "            10          -0.01208        0.988\n",
      "            11          -0.01205        0.988\n",
      "            12          -0.01204        0.988\n",
      "            13          -0.01204        0.988\n",
      "            14          -0.01203        0.988\n",
      "            15          -0.01203        0.988\n",
      "            16          -0.01203        0.988\n",
      "            17          -0.01203        0.988\n",
      "            18          -0.01203        0.988\n",
      "            19          -0.01203        0.988\n",
      "            20          -0.01203        0.988\n",
      "            21          -0.01203        0.988\n",
      "            22          -0.01203        0.988\n",
      "            23          -0.01203        0.988\n",
      "            24          -0.01203        0.988\n",
      "            25          -0.01203        0.988\n",
      "            26          -0.01203        0.988\n",
      "            27          -0.01203        0.988\n",
      "            28          -0.01203        0.988\n",
      "            29          -0.01203        0.988\n",
      "            30          -0.01203        0.988\n",
      "            31          -0.01203        0.988\n",
      "            32          -0.01203        0.988\n",
      "            33          -0.01203        0.988\n",
      "            34          -0.01203        0.988\n",
      "            35          -0.01203        0.988\n",
      "            36          -0.01203        0.988\n",
      "            37          -0.01203        0.988\n",
      "            38          -0.01203        0.988\n",
      "            39          -0.01203        0.988\n",
      "            40          -0.01203        0.988\n",
      "            41          -0.01203        0.988\n",
      "            42          -0.01203        0.988\n",
      "            43          -0.01203        0.988\n",
      "            44          -0.01203        0.988\n",
      "            45          -0.01203        0.988\n",
      "            46          -0.01203        0.988\n",
      "            47          -0.01203        0.988\n",
      "            48          -0.01203        0.988\n",
      "            49          -0.01203        0.988\n",
      "            50          -0.01203        0.988\n",
      "            51          -0.01203        0.988\n",
      "            52          -0.01203        0.988\n",
      "            53          -0.01203        0.988\n",
      "            54          -0.01203        0.988\n",
      "            55          -0.01203        0.988\n",
      "            56          -0.01203        0.988\n",
      "            57          -0.01203        0.988\n",
      "            58          -0.01203        0.988\n",
      "            59          -0.01203        0.988\n",
      "            60          -0.01203        0.988\n",
      "            61          -0.01203        0.988\n",
      "            62          -0.01203        0.988\n",
      "            63          -0.01203        0.988\n",
      "            64          -0.01203        0.988\n",
      "            65          -0.01203        0.988\n",
      "            66          -0.01203        0.988\n",
      "            67          -0.01203        0.988\n",
      "            68          -0.01203        0.988\n",
      "            69          -0.01203        0.988\n",
      "            70          -0.01203        0.988\n",
      "            71          -0.01203        0.988\n",
      "            72          -0.01203        0.988\n",
      "            73          -0.01203        0.988\n",
      "            74          -0.01203        0.988\n",
      "            75          -0.01203        0.988\n",
      "            76          -0.01203        0.988\n",
      "            77          -0.01203        0.988\n",
      "            78          -0.01203        0.988\n",
      "            79          -0.01203        0.988\n",
      "            80          -0.01203        0.988\n",
      "            81          -0.01203        0.988\n",
      "            82          -0.01203        0.988\n",
      "            83          -0.01203        0.988\n",
      "            84          -0.01203        0.988\n",
      "            85          -0.01203        0.988\n",
      "            86          -0.01203        0.988\n",
      "            87          -0.01203        0.988\n",
      "            88          -0.01203        0.988\n",
      "            89          -0.01203        0.988\n",
      "            90          -0.01203        0.988\n",
      "            91          -0.01203        0.988\n",
      "            92          -0.01203        0.988\n",
      "            93          -0.01203        0.988\n",
      "            94          -0.01203        0.988\n",
      "            95          -0.01203        0.988\n",
      "            96          -0.01203        0.988\n",
      "            97          -0.01203        0.988\n",
      "            98          -0.01203        0.988\n",
      "            99          -0.01203        0.988\n",
      "         Final          -0.01203        0.988\n",
      "Classifier evaluation: \n",
      "Precision: None\n",
      "Recall: 0.0\n",
      "F-measure: None\n"
     ]
    }
   ],
   "source": [
    "# MaxentClassifier\n",
    "# Hyper paramters\n",
    "CUT=True\n",
    "SAMPLE_SIZE=500\n",
    "RM_PONCTUATION=True\n",
    "RM_STOPWORDS=True\n",
    "LEMMATIZE=True\n",
    "\n",
    "run_classifier(MaxentClassifier, categories[2][2], CUT, SAMPLE_SIZE, RM_PONCTUATION, RM_STOPWORDS, LEMMATIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
